from sqlalchemy import create_engine, MetaData, Table, select, insert
from sqlalchemy.engine import Engine
from sqlalchemy.exc import SQLAlchemyError


def get_table(conn_str: str, schema_name: str, table_name: str):
    """
    ì£¼ì–´ì§„ DB ì—°ê²° ë¬¸ìì—´, ìŠ¤í‚¤ë§ˆëª…, í…Œì´ë¸”ëª…ì„ ì´ìš©í•´ Table ê°ì²´ë¥¼ ë°˜í™˜
    """
    engine = create_engine(conn_str)
    metadata = MetaData(schema=schema_name)
    metadata.reflect(bind=engine, only=[table_name])
    table = Table(table_name, metadata, autoload_with=engine)
    return table


def compare_table_structures(table1, table2):
    """
    ë‘ í…Œì´ë¸”ì˜ ì»¬ëŸ¼ êµ¬ì¡°ë¥¼ ë¹„êµ
    """
    cols1 = {c.name: str(c.type) for c in table1.columns}
    cols2 = {c.name: str(c.type) for c in table2.columns}

    only_in_1 = set(cols1.keys()) - set(cols2.keys())
    only_in_2 = set(cols2.keys()) - set(cols1.keys())
    diff_types = {
        k: (cols1[k], cols2[k])
        for k in set(cols1.keys()) & set(cols2.keys())
        if cols1[k] != cols2[k]
    }

    return {"only_in_1": only_in_1, "only_in_2": only_in_2, "diff_types": diff_types}


def transfer_data(conn_str_src, schema_src, table_src,
                  conn_str_dst, schema_dst, table_dst,
                  where_clause=None):
    """
    src â†’ dst ë°ì´í„° ì´ê´€
    """
    engine_src = create_engine(conn_str_src)
    engine_dst = create_engine(conn_str_dst)

    src_table = get_table(conn_str_src, schema_src, table_src)
    dst_table = get_table(conn_str_dst, schema_dst, table_dst)

    # --- êµ¬ì¡° ë¹„êµ ---
    diff = compare_table_structures(src_table, dst_table)
    if diff["only_in_1"] or diff["only_in_2"] or diff["diff_types"]:
        print("âš ï¸ í…Œì´ë¸” êµ¬ì¡°ê°€ ì™„ì „íˆ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        print(diff)
        return

    # --- ë°ì´í„° ì„ íƒ ---
    with engine_src.connect() as conn_src:
        stmt = select(src_table)
        if where_clause is not None:
            stmt = stmt.where(where_clause)
        result = conn_src.execute(stmt)
        rows = [dict(row._mapping) for row in result]

    # --- ë°ì´í„° ì‚½ì… ---
    if not rows:
        print("ğŸ“­ ì „ì†¡í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    with engine_dst.begin() as conn_dst:
        try:
            conn_dst.execute(insert(dst_table), rows)
            print(f"âœ… {len(rows)}ê°œ í–‰ì„ {table_dst}ì— ì‚½ì…í–ˆìŠµë‹ˆë‹¤.")
        except SQLAlchemyError as e:
            print("âŒ ë°ì´í„° ì‚½ì… ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)


# ==============================
# ì˜ˆì‹œ ì‚¬ìš©ë²•
# ==============================

if __name__ == "__main__":
    conn_src = "postgresql+psycopg2://user1:pass1@192.168.1.10/db1"
    conn_dst = "postgresql+psycopg2://user2:pass2@192.168.1.20/db2"

    transfer_data(
        conn_str_src=conn_src,
        schema_src="public",
        table_src="customers",
        conn_str_dst=conn_dst,
        schema_dst="public",
        table_dst="customers_backup",
        where_clause=None  # ì˜ˆ: text("id > 100")
    )





    from sqlalchemy import create_engine, select, insert, func
from sqlalchemy.exc import SQLAlchemyError

def transfer_data(conn_str_src, schema_src, table_src,
                  conn_str_dst, schema_dst, table_dst,
                  where_clause=None, chunk_size=1000):
    engine_src = create_engine(conn_str_src)
    engine_dst = create_engine(conn_str_dst)

    src_table = get_table(conn_str_src, schema_src, table_src)
    dst_table = get_table(conn_str_dst, schema_dst, table_dst)

    # --- row count ê³„ì‚° ---
    with engine_src.connect() as conn_src:
        stmt_count = select(func.count()).select_from(src_table)
        if where_clause is not None:
            stmt_count = stmt_count.where(where_clause)
        count = conn_src.execute(stmt_count).scalar()
        print(f"ğŸ” ì´ê´€ ëŒ€ìƒ í–‰ ìˆ˜: {count}")

    # --- chunk ë‹¨ìœ„ select/insert ---
    if count == 0:
        print("ğŸ“­ ì „ì†¡í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    transferred = 0
    with engine_src.connect() as conn_src, engine_dst.begin() as conn_dst:
        stmt = select(src_table)
        if where_clause is not None:
            stmt = stmt.where(where_clause)
        result = conn_src.execution_options(stream_results=True).execute(stmt)

        rows = []
        for row in result:
            rows.append(dict(row._mapping))
            if len(rows) >= chunk_size:
                try:
                    conn_dst.execute(insert(dst_table), rows)
                    transferred += len(rows)
                    print(f"âœ… {transferred}/{count} rows migrated")
                except SQLAlchemyError as e:
                    print("âŒ ë°ì´í„° ì‚½ì… ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)
                    raise
                rows = []
        if rows:  # ë‚¨ì€ row
            try:
                conn_dst.execute(insert(dst_table), rows)
                transferred += len(rows)
                print(f"âœ… {transferred}/{count} rows migrated")
            except SQLAlchemyError as e:
                print("âŒ ë°ì´í„° ì‚½ì… ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)

    print("ğŸ‰ ì´ê´€ ì™„ë£Œ!")


    from sqlalchemy import create_engine, MetaData, Table, insert, select
from sqlalchemy.schema import CreateTable
from sqlalchemy.exc import SQLAlchemyError

def clone_table_and_transfer_data(src_conn_str, dst_conn_str, schema, table_name, chunk_size=10000):    
    # 1. ì—”ì§„ ë° ë©”íƒ€ë°ì´í„°
    engine_src = create_engine(src_conn_str)
    engine_dst = create_engine(dst_conn_str)

    metadata_src = MetaData(schema=schema)
    metadata_src.reflect(bind=engine_src, only=[table_name])
    src_table = Table(table_name, metadata_src, autoload_with=engine_src)

    # 2. dstì— ë™ì¼ í…Œì´ë¸” ìƒì„±
    metadata_dst = MetaData(schema=schema)
    dst_table = Table(table_name, metadata_dst)

    # dst DBì— í…Œì´ë¸” ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    if not engine_dst.dialect.has_table(engine_dst.connect(), table_name, schema=schema):
        ddl = str(CreateTable(src_table).compile(engine_dst))
        print("ğŸ”¨ Creating table in dst:\n", ddl)
        with engine_dst.begin() as conn:
            conn.execute(CreateTable(src_table))
        print(f"âœ… {table_name} í…Œì´ë¸” ìƒì„± ì™„ë£Œ")

    # dst_table ê°ì²´ ì¬ë°˜ì˜
    metadata_dst.reflect(bind=engine_dst, only=[table_name])
    dst_table = Table(table_name, metadata_dst, autoload_with=engine_dst)

    # 3. ë°ì´í„° ì´ê´€
    with engine_src.connect() as conn_src:
        count = conn_src.execute(select(src_table.count())).scalar()
        print(f"ğŸšš ì „ì²´ ì´ê´€ ëŒ€ìƒ í–‰: {count}")

        stmt = select(src_table)
        result = conn_src.execution_options(stream_results=True).execute(stmt)

        rows, transferred = [], 0
        with engine_dst.begin() as conn_dst:
            for row in result:
                rows.append(dict(row._mapping))
                if len(rows) >= chunk_size:
                    conn_dst.execute(insert(dst_table), rows)
                    transferred += len(rows)
                    print(f"ğŸ”„ {transferred}/{count} rows migrated")
                    rows = []
            if rows:
                conn_dst.execute(insert(dst_table), rows)
                transferred += len(rows)
                print(f"ğŸ”„ {transferred}/{count} rows migrated")
        print(f"ğŸ‰ ì´ê´€ ì™„ë£Œ! ì´ {transferred} rows.")
