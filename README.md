from sqlalchemy import create_engine, MetaData, Table, select, insert
from sqlalchemy.engine import Engine
from sqlalchemy.exc import SQLAlchemyError


def get_table(conn_str: str, schema_name: str, table_name: str):
    """
    ì£¼ì–´ì§„ DB ì—°ê²° ë¬¸ìì—´, ìŠ¤í‚¤ë§ˆëª…, í…Œì´ë¸”ëª…ì„ ì´ìš©í•´ Table ê°ì²´ë¥¼ ë°˜í™˜
    """
    engine = create_engine(conn_str)
    metadata = MetaData(schema=schema_name)
    metadata.reflect(bind=engine, only=[table_name])
    table = Table(table_name, metadata, autoload_with=engine)
    return table


def compare_table_structures(table1, table2):
    """
    ë‘ í…Œì´ë¸”ì˜ ì»¬ëŸ¼ êµ¬ì¡°ë¥¼ ë¹„êµ
    """
    cols1 = {c.name: str(c.type) for c in table1.columns}
    cols2 = {c.name: str(c.type) for c in table2.columns}

    only_in_1 = set(cols1.keys()) - set(cols2.keys())
    only_in_2 = set(cols2.keys()) - set(cols1.keys())
    diff_types = {
        k: (cols1[k], cols2[k])
        for k in set(cols1.keys()) & set(cols2.keys())
        if cols1[k] != cols2[k]
    }

    return {"only_in_1": only_in_1, "only_in_2": only_in_2, "diff_types": diff_types}


def transfer_data(conn_str_src, schema_src, table_src,
                  conn_str_dst, schema_dst, table_dst,
                  where_clause=None):
    """
    src â†’ dst ë°ì´í„° ì´ê´€
    """
    engine_src = create_engine(conn_str_src)
    engine_dst = create_engine(conn_str_dst)

    src_table = get_table(conn_str_src, schema_src, table_src)
    dst_table = get_table(conn_str_dst, schema_dst, table_dst)

    # --- êµ¬ì¡° ë¹„êµ ---
    diff = compare_table_structures(src_table, dst_table)
    if diff["only_in_1"] or diff["only_in_2"] or diff["diff_types"]:
        print("âš ï¸ í…Œì´ë¸” êµ¬ì¡°ê°€ ì™„ì „íˆ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        print(diff)
        return

    # --- ë°ì´í„° ì„ íƒ ---
    with engine_src.connect() as conn_src:
        stmt = select(src_table)
        if where_clause is not None:
            stmt = stmt.where(where_clause)
        result = conn_src.execute(stmt)
        rows = [dict(row._mapping) for row in result]

    # --- ë°ì´í„° ì‚½ì… ---
    if not rows:
        print("ğŸ“­ ì „ì†¡í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    with engine_dst.begin() as conn_dst:
        try:
            conn_dst.execute(insert(dst_table), rows)
            print(f"âœ… {len(rows)}ê°œ í–‰ì„ {table_dst}ì— ì‚½ì…í–ˆìŠµë‹ˆë‹¤.")
        except SQLAlchemyError as e:
            print("âŒ ë°ì´í„° ì‚½ì… ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)


# ==============================
# ì˜ˆì‹œ ì‚¬ìš©ë²•
# ==============================

if __name__ == "__main__":
    conn_src = "postgresql+psycopg2://user1:pass1@192.168.1.10/db1"
    conn_dst = "postgresql+psycopg2://user2:pass2@192.168.1.20/db2"

    transfer_data(
        conn_str_src=conn_src,
        schema_src="public",
        table_src="customers",
        conn_str_dst=conn_dst,
        schema_dst="public",
        table_dst="customers_backup",
        where_clause=None  # ì˜ˆ: text("id > 100")
    )





    from sqlalchemy import create_engine, select, insert, func
from sqlalchemy.exc import SQLAlchemyError

def transfer_data(conn_str_src, schema_src, table_src,
                  conn_str_dst, schema_dst, table_dst,
                  where_clause=None, chunk_size=1000):
    engine_src = create_engine(conn_str_src)
    engine_dst = create_engine(conn_str_dst)

    src_table = get_table(conn_str_src, schema_src, table_src)
    dst_table = get_table(conn_str_dst, schema_dst, table_dst)

    # --- row count ê³„ì‚° ---
    with engine_src.connect() as conn_src:
        stmt_count = select(func.count()).select_from(src_table)
        if where_clause is not None:
            stmt_count = stmt_count.where(where_clause)
        count = conn_src.execute(stmt_count).scalar()
        print(f"ğŸ” ì´ê´€ ëŒ€ìƒ í–‰ ìˆ˜: {count}")

    # --- chunk ë‹¨ìœ„ select/insert ---
    if count == 0:
        print("ğŸ“­ ì „ì†¡í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    transferred = 0
    with engine_src.connect() as conn_src, engine_dst.begin() as conn_dst:
        stmt = select(src_table)
        if where_clause is not None:
            stmt = stmt.where(where_clause)
        result = conn_src.execution_options(stream_results=True).execute(stmt)

        rows = []
        for row in result:
            rows.append(dict(row._mapping))
            if len(rows) >= chunk_size:
                try:
                    conn_dst.execute(insert(dst_table), rows)
                    transferred += len(rows)
                    print(f"âœ… {transferred}/{count} rows migrated")
                except SQLAlchemyError as e:
                    print("âŒ ë°ì´í„° ì‚½ì… ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)
                    raise
                rows = []
        if rows:  # ë‚¨ì€ row
            try:
                conn_dst.execute(insert(dst_table), rows)
                transferred += len(rows)
                print(f"âœ… {transferred}/{count} rows migrated")
            except SQLAlchemyError as e:
                print("âŒ ë°ì´í„° ì‚½ì… ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)

    print("ğŸ‰ ì´ê´€ ì™„ë£Œ!")


    from sqlalchemy import create_engine, MetaData, Table, insert, select
from sqlalchemy.schema import CreateTable
from sqlalchemy.exc import SQLAlchemyError

def clone_table_and_transfer_data(src_conn_str, dst_conn_str, schema, table_name, chunk_size=10000):    
    # 1. ì—”ì§„ ë° ë©”íƒ€ë°ì´í„°
    engine_src = create_engine(src_conn_str)
    engine_dst = create_engine(dst_conn_str)

    metadata_src = MetaData(schema=schema)
    metadata_src.reflect(bind=engine_src, only=[table_name])
    src_table = Table(table_name, metadata_src, autoload_with=engine_src)

    # 2. dstì— ë™ì¼ í…Œì´ë¸” ìƒì„±
    metadata_dst = MetaData(schema=schema)
    dst_table = Table(table_name, metadata_dst)

    # dst DBì— í…Œì´ë¸” ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    if not engine_dst.dialect.has_table(engine_dst.connect(), table_name, schema=schema):
        ddl = str(CreateTable(src_table).compile(engine_dst))
        print("ğŸ”¨ Creating table in dst:\n", ddl)
        with engine_dst.begin() as conn:
            conn.execute(CreateTable(src_table))
        print(f"âœ… {table_name} í…Œì´ë¸” ìƒì„± ì™„ë£Œ")

    # dst_table ê°ì²´ ì¬ë°˜ì˜
    metadata_dst.reflect(bind=engine_dst, only=[table_name])
    dst_table = Table(table_name, metadata_dst, autoload_with=engine_dst)

    # 3. ë°ì´í„° ì´ê´€
    with engine_src.connect() as conn_src:
        count = conn_src.execute(select(src_table.count())).scalar()
        print(f"ğŸšš ì „ì²´ ì´ê´€ ëŒ€ìƒ í–‰: {count}")

        stmt = select(src_table)
        result = conn_src.execution_options(stream_results=True).execute(stmt)

        rows, transferred = [], 0
        with engine_dst.begin() as conn_dst:
            for row in result:
                rows.append(dict(row._mapping))
                if len(rows) >= chunk_size:
                    conn_dst.execute(insert(dst_table), rows)
                    transferred += len(rows)
                    print(f"ğŸ”„ {transferred}/{count} rows migrated")
                    rows = []
            if rows:
                conn_dst.execute(insert(dst_table), rows)
                transferred += len(rows)
                print(f"ğŸ”„ {transferred}/{count} rows migrated")
        print(f"ğŸ‰ ì´ê´€ ì™„ë£Œ! ì´ {transferred} rows.")



from sqlalchemy import create_engine, MetaData, Table, insert, select, func
from sqlalchemy.schema import CreateTable
from sqlalchemy.exc import SQLAlchemyError

def clone_table_and_transfer_data(
    src_conn_str, src_schema, table_name, 
    dst_conn_str, dst_schema,
    chunk_size=10000
):    
    # 1. ì—”ì§„ ë° ë©”íƒ€ë°ì´í„°
    engine_src = create_engine(src_conn_str)
    engine_dst = create_engine(dst_conn_str)

    metadata_src = MetaData(schema=src_schema)
    metadata_src.reflect(bind=engine_src, only=[table_name])
    src_table = Table(table_name, metadata_src, autoload_with=engine_src)

    # 2. dstì— ë™ì¼ í…Œì´ë¸” ìƒì„±
    # í…Œì´ë¸” ì •ì˜ë¥¼ ë³µì œí•˜ë˜, schemaë§Œ dst_schemaë¡œ ë°”ê¿ˆ
    table_ddl = CreateTable(src_table).compile(engine_dst)
    ddl_sql = str(table_ddl).replace(f'"{src_schema}".', f'"{dst_schema}".')
    print("ğŸ”¨ Creating table in dst (with different schema):\n", ddl_sql)
    with engine_dst.begin() as conn:
        conn.execute(ddl_sql)
    print(f"âœ… {dst_schema}.{table_name} í…Œì´ë¸” ìƒì„± ì™„ë£Œ")

    # dst_table ê°ì²´ ì¬ë°˜ì˜
    metadata_dst = MetaData(schema=dst_schema)
    metadata_dst.reflect(bind=engine_dst, only=[table_name])
    dst_table = Table(table_name, metadata_dst, autoload_with=engine_dst)

    # 3. ë°ì´í„° ì´ê´€
    with engine_src.connect() as conn_src:
        count = conn_src.execute(select(func.count()).select_from(src_table)).scalar()
        print(f"ğŸšš ì „ì²´ ì´ê´€ ëŒ€ìƒ í–‰: {count}")

        stmt = select(src_table)
        result = conn_src.execution_options(stream_results=True).execute(stmt)

        rows, transferred = [], 0
        with engine_dst.begin() as conn_dst:
            for row in result:
                rows.append(dict(row._mapping))
                if len(rows) >= chunk_size:
                    conn_dst.execute(insert(dst_table), rows)
                    transferred += len(rows)
                    print(f"ğŸ”„ {transferred}/{count} rows migrated")
                    rows = []
            if rows:
                conn_dst.execute(insert(dst_table), rows)
                transferred += len(rows)
                print(f"ğŸ”„ {transferred}/{count} rows migrated")
        print(f"ğŸ‰ ì´ê´€ ì™„ë£Œ! ì´ {transferred} rows.")


langgraphë¡œ ë§Œë“¤ì–´ì§„ ì½”ë“œë“¤ì´ ìˆë‹¤. ì¼ë¶€ë¥¼ ë³´ì—¬ì¤„í…Œë‹ˆ ë‚´ê°€ ê¶ê¸ˆí•œê²ƒì„ ì„¤ëª…í•´ë¼.
initial_state: IntentAnalysisState = {
"user_question": "test"
"persona_state":{
"curplanid": "222P"
...
}
...
}
planner_builder = build_planner()
planner_graph = planner_builder.compile()
config = RunnableConfig(recursion_limit=10, configurable={"thread_id":str(uuid.uuid4)))})
planner_graph.invoke(initial_state, config=config)

ì´ê²Œ í…ŒìŠ¤íŠ¸ ì½”ë“œë¡œ ë“¤ì–´ì™€ìˆë‹¤.

ë‚˜ëŠ” ì–´ë–¤ê²ƒì„ ì›í•˜ëƒë©´, apiìš”ì²­ì´ ë“¤ì–´ì™”ì„ ë•Œ ì´ ì •ë³´ë¥¼ ìª¼ê°œì„œ ê·¸ë˜í”„ë¥¼ invokeí•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ë‹¤ì‹œ í¸ì§‘í•´ responseì— ë‹´ì•„ì•¼ í•œë‹¤. IntentAnalysisStateëŠ” typedictì´ë‹¤.

ì¥ê³  ê¸°ë°˜ìœ¼ë¡œ viewë¥¼ ì •ì˜í•´ë†“ì•˜ê³ , ì—¬ê¸° ì—°ê²°í™”ê¸° ìœ„í•´ì„œ advisor(request_dict)ë¼ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ì—¬ returnê°’ì„ true, result, none, none ì´ë ‡ê²Œ ë³´ë‚¼ ê²ƒì´ë‹¤.
ì´ í•¨ìˆ˜ ì•ˆì— request_dictë¥¼ ë¶„í•´í•˜ì—¬ ì´ˆê¸° IntentAnalysisStateê°ì²´ë¥¼ ë§Œë“¤ê³ , ì´ë¥¼ í™œìš©í•´ graphë¥¼ buildí•˜ì—¬ invokeí•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ê°ì²´ì— ë‹´ì•„ ì´ë¥¼ ë¶„ì„í•´ responseë¥¼ ë§Œë“œëŠ” ê²ƒ. ì´ê²ƒì€ ì •ìƒì ì¸ í”„ë¡œì„¸ìŠ¤ë¼ê³  ë³¼ìˆ˜ìˆëŠ”ì§€? ë§Œì•½ ê·¸ë ‡ë‹¤ë©´ ì˜ˆì‹œ advisor(request_dict)ë¥¼ ì‘ì„±í•´ë´ë¼. ì–´ë–»ê²Œ í•˜ëƒë©´

ê·¸ë˜í”„ëŠ” ë¬´ì¡°ê±´ ìš”ì²­ë§ˆë‹¤ build/compileí•œë‹¤.
ì£¼ìš” ë¶„ê¸°ì ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. request_dictì— threadidê°’ì´ ìˆë‹¤ë©´, í•´ë‹¹ ê°’ì„ ì‚¬ìš©í•œë‹¤. ë§Œì•½ì— ì—†ë‹¤ë©´, thread_idë¥¼ ìƒˆë¡œ ìƒì„±í•œë‹¤. request_dictì˜ Input.Typeê°’ì´ chatì´ë¼ë©´, input.valueê°’ì„ user_questionë³€ìˆ˜ì— ë„£ëŠ”ë‹¤
ì´ ì •ë³´ë“¤ë¡œ intentAnalysisState ê°ì²´ë¥¼ ìƒì„±í•˜ê³ , ê·¸ë˜í”„ ë¹Œë“œ ë° ì¸ë³´í¬í•˜ì—¬, ê²°ê³¼ë¥¼ jsoníŒŒì¼ë¡œ ì €ì¥í•œë‹¤. ë‚˜ë¨¸ì§€ëŠ” ì´ ì €ì¥ëœ íŒŒì¼ì„ í•´ì„ í›„ ê²°ì •í•˜ê² ë‹¤.

ìš”êµ¬í•˜ì‹  íë¦„ì€ ì¼ë°˜ì ìœ¼ë¡œ ë§ìŠµë‹ˆë‹¤. ìš”ì²­ì„ ë°›ì•„ ì´ˆê¸° IntentAnalysisStateë¥¼ êµ¬ì„± â†’ ê·¸ë˜í”„ build/compile â†’ invoke â†’ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥ â†’ ìƒìœ„ ë ˆì´ì–´ëŠ” ì €ì¥ íŒŒì¼ì„ í•´ì„í•´ ì‘ë‹µ êµ¬ì„±. ë‹¨, ìš”ì²­ë§ˆë‹¤ build/compileì€ ë¹„ìš©ì´ í¬ë¯€ë¡œ íŠ¸ë˜í”½ì´ ë§ë‹¤ë©´ ìºì‹œ/ì‹±ê¸€í„´ìœ¼ë¡œ ìµœì í™”í•˜ëŠ” ê²Œ ë³´í†µì´ì§€ë§Œ, ì§€ê¸ˆì€ â€œìš”ì²­ë§ˆë‹¤ build/compileâ€ ì¡°ê±´ëŒ€ë¡œ ì˜ˆì‹œë¥¼ ë“œë¦½ë‹ˆë‹¤.

ì˜ˆì‹œ advisor(request_dict)
- ê·œì¹™
  - threadidê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
  - Input.Type == "chat"ì´ë©´ Input.valueë¥¼ user_questionì— ë§¤í•‘
  - IntentAnalysisStateëŠ” ì—¬ëŸ¬ë¶„ í”„ë¡œì íŠ¸ì˜ TypedDict ì •ì˜ë¥¼ ì‚¬ìš©
  - ê·¸ë˜í”„ëŠ” ìš”ì²­ë§ˆë‹¤ build/compile
  - ê²°ê³¼ëŠ” JSON íŒŒì¼ë¡œ ì €ì¥
  - ë°˜í™˜í˜•: (True, result_dict, None, None) ë˜ëŠ” ì‹¤íŒ¨ ì‹œ (False, None, err_msg, None)

ì½”ë“œ ì˜ˆì‹œ (í•„ìš”í•œ import/ê²½ë¡œëŠ” í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •)
```python
import os
import json
import uuid
from datetime import datetime
from typing import Any, Dict, Tuple, Optional

from langchain_core.runnables import RunnableConfig

# ì—¬ëŸ¬ë¶„ í”„ë¡œì íŠ¸ì˜ íƒ€ì…/ë¹Œë” importë¡œ êµì²´í•˜ì„¸ìš”.
# from your_project.langgraph.types import IntentAnalysisState
# from your_project.langgraph.builder import build_planner

# ì˜ˆ: settings ê¸°ë°˜ ê²½ë¡œ ì‚¬ìš©ì„ ì›í•˜ë©´ ì£¼ì„ í•´ì œ
# from django.conf import settings

def _ensure_dir(path: str) -> None:
    if not os.path.exists(path):
        os.makedirs(path, exist_ok=True)

def _to_jsonable(obj: Any) -> Any:
    # LangGraph stateì— ë¹„ì§ë ¬í™” ê°ì²´ê°€ ì„ì¼ ìˆ˜ ìˆì–´ ë°©ì–´ì ìœ¼ë¡œ ì²˜ë¦¬
    try:
        json.dumps(obj)
        return obj
    except TypeError:
        if isinstance(obj, dict):
            return {k: _to_jsonable(v) for k, v in obj.items()}
        if isinstance(obj, (list, tuple)):
            return [_to_jsonable(v) for v in obj]
        if hasattr(obj, "model_dump"):
            return obj.model_dump()  # pydantic v2
        if hasattr(obj, "dict"):
            return obj.dict()  # pydantic v1
        if hasattr(obj, "__dict__"):
            return {k: _to_jsonable(v) for k, v in obj.__dict__.items()}
        return str(obj)

def advisor(request_dict: Dict[str, Any]) -> Tuple[bool, Optional[Dict[str, Any]], Optional[str], Optional[str]]:
    """
    ìš”ì²­ì„ ë¶„í•´í•´ IntentAnalysisState ì´ˆê¸°í™” â†’ LangGraph build/compile â†’ invoke â†’ ê²°ê³¼ JSON ì €ì¥.
    ì„±ê³µ ì‹œ (True, result_dict, None, None) ë°˜í™˜.
    ì‹¤íŒ¨ ì‹œ (False, None, error_message, None) ë°˜í™˜.
    """
    try:
        # 1) thread_id ê²°ì •
        thread_id = request_dict.get("threadid")
        if not thread_id:
            thread_id = str(uuid.uuid4())

        # 2) user_question ì¶”ì¶œ (Input.Type == "chat"ì¼ ë•Œë§Œ)
        user_question = ""
        input_obj = request_dict.get("Input") or request_dict.get("input") or {}
        if isinstance(input_obj, dict) and str(input_obj.get("Type") or input_obj.get("type")).lower() == "chat":
            user_question = input_obj.get("value") or ""

        # 3) persona_state ë“± ë‚˜ë¨¸ì§€ ìƒíƒœ êµ¬ì„±
        #    - í”„ë¡œì íŠ¸ì˜ TypedDict í•„ìˆ˜ í•„ë“œì— ë§ê²Œ ê¸°ë³¸ê°’/ì „ë‹¬ê°’ì„ ì±„ì›Œì£¼ì„¸ìš”.
        #    - ì˜ˆ: persona_stateëŠ” ìš”ì²­ì— ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’.
        persona_state = request_dict.get("persona_state") or {
            "curplanid": request_dict.get("curplanid", None)
        }

        # ì¶”ê°€ë¡œ í•„ìš”í•œ ìƒíƒœ í•„ë“œê°€ ìˆë‹¤ë©´ ì—¬ê¸°ì„œ ì±„ì›ë‹ˆë‹¤.
        # ì˜ˆì‹œ placeholder:
        # other_state = request_dict.get("other_state", {})

        # ì´ˆê¸° IntentAnalysisState êµ¬ì„± (ì—¬ëŸ¬ë¶„ í”„ë¡œì íŠ¸ì˜ TypedDict êµ¬ì¡°ë¥¼ ë”°ë¥´ì„¸ìš”)
        initial_state: Dict[str, Any] = {
            "user_question": user_question,
            "persona_state": persona_state,
            # "other_state": other_state,
            # í•„ìš” í•„ë“œ ë” ì¶”ê°€
        }

        # 4) ê·¸ë˜í”„ build/compile (ìš”ì²­ë§ˆë‹¤)
        planner_builder = build_planner()
        planner_graph = planner_builder.compile()

        # 5) config êµ¬ì„± ë° invoke
        config = RunnableConfig(
            recursion_limit=10,
            configurable={"thread_id": thread_id}
        )
        graph_result = planner_graph.invoke(initial_state, config=config)

        # 6) JSON íŒŒì¼ë¡œ ì €ì¥
        # output_base = getattr(settings, "LANGGRAPH_OUTPUT_DIR", os.path.join(settings.BASE_DIR, "langgraph_results"))
        output_base = os.path.join(os.getcwd(), "langgraph_results")  # í•„ìš” ì‹œ settingsë¡œ êµì²´
        _ensure_dir(output_base)

        timestamp = datetime.utcnow().strftime("%Y%m%dT%H%M%S%fZ")
        filename = f"{timestamp}_{thread_id}.json"
        output_path = os.path.join(output_base, filename)

        payload = {
            "thread_id": thread_id,
            "initial_state": _to_jsonable(initial_state),
            "graph_result": _to_jsonable(graph_result),
            "meta": {
                "recursion_limit": 10,
                "saved_at": timestamp,
            },
        }

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(payload, f, ensure_ascii=False, indent=2)

        # 7) ìƒìœ„ì—ì„œ íŒŒì¼ì„ í•´ì„í•œë‹¤ê³  í•˜ì…¨ìœ¼ë¯€ë¡œ ê²½ë¡œ/ë©”íƒ€ë§Œ ë¦¬í„´
        result = {
            "thread_id": thread_id,
            "result_file": output_path,
        }
        return True, result, None, None

    except Exception as e:
        # ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ ì „ë‹¬
        return False, None, f"advisor failed: {e}", None
```

ì„¤ëª… ìš”ì•½
- ìœ„ í•¨ìˆ˜ëŠ” ìš”ì²­ì„ í•´ì„í•´ IntentAnalysisStateë¥¼ ë§Œë“¤ê³ , ë¹Œë”ë¥¼ ë§¤ ìš”ì²­ë§ˆë‹¤ build/compile í›„ invokeí•©ë‹ˆë‹¤.
- threadidëŠ” ìš”ì²­ì˜ threadidê°€ ìˆìœ¼ë©´ ì¬ì‚¬ìš©, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.
- Input.Typeì´ chatì´ë©´ Input.valueë¥¼ user_questionì— ë§¤í•‘í•©ë‹ˆë‹¤.
- invoke ê²°ê³¼ì™€ ì´ˆê¸° ìƒíƒœë¥¼ í•¨ê»˜ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤. ìƒìœ„ì—ì„œëŠ” í•´ë‹¹ íŒŒì¼ì„ ì½ì–´ í•´ì„í•˜ì‹œë©´ ë©ë‹ˆë‹¤.
- TypedDict í•„ìˆ˜ í•„ë“œëŠ” í”„ë¡œì íŠ¸ ì •ì˜ì— ë§ê²Œ initial_state ë¶€ë¶„ì„ ë³´ì™„í•˜ì„¸ìš”.


ì•„ë˜ëŠ” result(dict[str, Any])ì—ì„œ â€œë‘ ë²ˆì§¸ ë ˆë²¨ì— ìˆëŠ” 'test'â€ë¥¼ ì°¾ì•„ ê·¸ í•˜ìœ„ì˜ 'E3' ê°’ì„ ë³€ìˆ˜ì— ë‹´ì•„ ì¶œë ¥í•˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤.

ì˜ˆì‹œ 1) ì²« ë²ˆì§¸ë¡œ ë°œê²¬ëœ 'test'ì˜ 'E3'ë§Œ ê°€ì ¸ì˜¤ê¸°
```python
# result = planner_graph.invoke(...)
# resultëŠ” dict[str, Any]

test_dict = None
e3_value = None

for _, second_level in result.items():
    if isinstance(second_level, dict) and 'test' in second_level:
        test_dict = second_level['test']
        if isinstance(test_dict, dict) and 'E3' in test_dict:
            e3_value = test_dict['E3']
        break  # ì²« ë§¤ì¹˜ë§Œ ì‚¬ìš©í•˜ë ¤ë©´ break

print(e3_value)
```

ì˜ˆì‹œ 2) ëª¨ë“  ë‘ ë²ˆì§¸ ë ˆë²¨ì˜ 'test'ì—ì„œ 'E3'ë¥¼ ëª¨ì•„ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ê°€ì ¸ì˜¤ê¸°
```python
# result = planner_graph.invoke(...)

e3_values = [
    lvl2['test']['E3']
    for lvl2 in result.values()
    if isinstance(lvl2, dict)
    and isinstance(lvl2.get('test'), dict)
    and 'E3' in lvl2['test']
]

print(e3_values)  # ì—¬ëŸ¬ ê°œë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶œë ¥
```

í•„ìš” ì‹œ KeyErrorë¥¼ í”¼í•˜ê¸° ìœ„í•´ isinstanceì™€ in ì²´í¬ë¥¼ ìœ ì§€í•˜ë©´ ì•ˆì „í•˜ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.



def to_table_html(data):
    """
    ì£¼ì–´ì§„ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ë°ì´í„°ë¥¼ HTML í…Œì´ë¸” ì½”ë“œë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜.
    
    Args:
    - data (list of dict): í…Œì´ë¸” í–‰ ë°ì´í„°ë¥¼ í¬í•¨í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ë“¤ì˜ ë¦¬ìŠ¤íŠ¸.
    
    Returns:
    - str: HTML í˜•ì‹ì˜ í…Œì´ë¸” ì½”ë“œë¥¼ ë°˜í™˜.
    """
    
    if not data:
        return "<table></table>"

    # ë¦¬ìŠ¤íŠ¸ì˜ ì²« ë²ˆì§¸ ë”•ì…”ë„ˆë¦¬ì—ì„œ í‚¤ë¥¼ ì–»ì–´ í…Œì´ë¸” í—¤ë” ìƒì„±
    headers = data[0].keys()
    header_html = "<tr>" + "".join(f"<th>{key}</th>" for key in headers) + "</tr>"

    # ê° ë”•ì…”ë„ˆë¦¬ì—ì„œ ê°’ì„ ì¶”ì¶œí•˜ì—¬ í…Œì´ë¸”ì˜ ë°ì´í„° í–‰ ìƒì„±
    rows_html = ""
    for row in data:
        row_html = "<tr>" + "".join(f"<td>{row[col]}</td>" for col in headers) + "</tr>"
        rows_html += row_html

    # ìµœì¢… HTML í…Œì´ë¸” ì½”ë“œ ì¡°ë¦½
    table_html = f"<table border='1'>{header_html}{rows_html}</table>"
    
    return table_html

# ì˜ˆì‹œ ë°ì´í„°
data = [
    {"id": "myuser1", "name": "choi"},
    {"id": "myuser2", "name": "ch"},
    # ... ì¶”ê°€ ë°ì´í„°
]

# í•¨ìˆ˜ ì‹¤í–‰ ë° ê²°ê³¼ ì¶œë ¥
html_snippet = to_table_html(data)
print(html_snippet)
